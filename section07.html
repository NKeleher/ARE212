<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Section 7: GLS</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ARE 212</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Section notes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="notes.html">Table of Contents</a>
    </li>
    <li>
      <a href="section00.html">Section 0</a>
    </li>
    <li>
      <a href="section01.html">Section 1</a>
    </li>
    <li>
      <a href="section02.html">Section 2</a>
    </li>
    <li>
      <a href="section03.html">Section 3</a>
    </li>
    <li>
      <a href="section04.html">Section 4</a>
    </li>
    <li>
      <a href="section05.html">Section 5</a>
    </li>
    <li>
      <a href="section06.html">Section 6</a>
    </li>
    <li>
      <a href="section07.html">Section 7</a>
    </li>
    <li>
      <a href="latexKnitr.html">LaTeX and knitr</a>
    </li>
  </ul>
</li>
<li>
  <a href="courseInfo.html">Course Info</a>
</li>
<li>
  <a href="syllabi.html">Syllabi</a>
</li>
<li>
  <a href="resources.html">R Resources</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="contact.html">
    <span class="fa fa-envelope-o fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/edrubin/ARE212">
    <span class="fa fa-github-square fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://edrub.in">
    <span class="fa fa-hand-peace-o fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Section 7: GLS</h1>

</div>


<p><br></p>
<div id="admin" class="section level1">
<h1>Admin</h1>
<div id="new-this-week" class="section level2">
<h2>New this week</h2>
<p>Starting this week, I am going to introduce you to a few tools that I’ve found useful for empirically minded economic research.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Feel free to ask for specific topics or to make recommendations of your own. I’ll include this part last in the section notes, as it is not as much of a priority as learning to code in R.</p>
</div>
<div id="problem-set-1" class="section level2">
<h2>Problem set 1</h2>
<p>After grading your problem sets, I have a few comments/requests:</p>
<ol start="0" style="list-style-type: decimal">
<li>Overall, great job! Solid coding and, for the most part, nice discussions when the problem set requested them.</li>
<li>Our strict exogeneity assumption is about the <em>conditional</em> mean of the disturbance term. The <em>unconditional</em> mean of the residuals will always be zero when you estimate via OLS with an intercept. The residuals will (generally) have a non-zero (<em>unconditional</em>) mean when you exclude the intercept.</li>
<li>Our assumption about linearity is about the parameters and the disturbance—not the covariates (meaning squaring a covariate is fair game).</li>
<li>When you demean your data, you’ve applied the FWL theorem and do not need an intercept.</li>
<li>Please separate your answers outside of your R comments/code. And please don’t answer the questions in your R comments.</li>
</ol>
</div>
<div id="what-you-will-need" class="section level2">
<h2>What you will need</h2>
<p><strong>Packages</strong>:</p>
<ul>
<li>Previously used: <code>dplyr</code>, <code>lfe</code>, <code>readr</code>, <code>magrittr</code>, <code>parallel</code>, <code>lfe</code>, <code>ggplot2</code>, <code>ggthemes</code>, <code>viridis</code></li>
</ul>
</div>
<div id="last-week" class="section level2">
<h2>Last week</h2>
<p><a href="section06.html">Last week</a> we discussed the fantastic figure-making package <code>ggplot2</code>.</p>
<p><strong>Follow up</strong>: <code>ggplot2</code> has a helpful function named <code>qplot()</code>. <code>qplot()</code> is less customizable than the standard functions that you stack on top of <code>ggplot()</code>, and it deviates from the syntax. So why am I telling you about it? Because it is nice for making quick graphs.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ggplot2::<span class="kw">qplot</span>(<span class="dt">x =</span> <span class="kw">rnorm</span>(<span class="dv">100</span>), <span class="dt">y =</span> <span class="kw">rnorm</span>(<span class="dv">100</span>), <span class="dt">geom =</span> <span class="st">&quot;point&quot;</span>)</code></pre></div>
<p><img src="section07_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>I still think the standard <code>ggplot() + ...</code> functionality is best, but if you want to make a quick plot, <code>qplot()</code> can be helpful.</p>
</div>
<div id="this-week" class="section level2">
<h2>This week</h2>
<p>This week we will cover generalized least squares (GLS), focusing on a special case called weighted least squares (WLS). And we will run more simulations (with pretty graphs)!</p>
</div>
</div>
<div id="gls" class="section level1">
<h1>GLS</h1>
<p>Up to this point, we have stuck with ordinary least squares (OLS). Today, we will talk about generalized least squares (GSL). Specifically, we will discuss weighted least squares (WLS), which—as in the case with OLS—is a special case of GLS.</p>
<div id="blue-estimators" class="section level2">
<h2>BLUE estimators</h2>
<p>Let’s return to OLS land for a moment: we assumed our errors are spherical—homoskedastic and uncorrelated—which we can also write</p>
<p><span class="math display">\[ \mathop{\boldsymbol{E}} \left[ \boldsymbol{\varepsilon} \boldsymbol{\varepsilon}^\prime | \mathbf{X} \right] = \sigma^2 \mathbf{I}_n \]</span></p>
<p>Under this assumption, we showed OLS is BLUE (best<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> linear unbiased estimator). But as you saw in your first problem set, there are times where our errors are not exactly spherical. What happens in this case—<em>i.e.</em>, what happens when we relax our spherical-error assumption? OLS is still unbiased,<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> but it will no longer be BLUE (and your inferential statistics might be bad).</p>
<p>So where do we go from here? Instead of making the spherical error assumption, let’s make a generalized assumption about the disturbances:</p>
<p><span class="math display">\[ \mathop{\boldsymbol{E}}\left[ \boldsymbol{\varepsilon} \boldsymbol{\varepsilon}^\prime | \mathbf{X} \right] = \sigma^2 \boldsymbol{\Omega}(\mathbf{X}) \]</span></p>
<p>If <span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span> is known and positive definite, then GLS is BLUE (where the estimator is <span class="math inline">\(\left(\mathbf{X}^{\prime}\boldsymbol{\Omega}^{-1}\mathbf{X}\right)^{-1}\mathbf{X}^{\prime}\boldsymbol{\Omega}^{-1}\mathbf{y}\)</span>).<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> So, if you happen to know your disturbances are non-spherical (somewhat likely), and if you know the exact form of <span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span> (somewhat unlikely), then you should opt for GLS. Why? GLS is the more efficient estimator in this world. (Recall the <em>b</em> in BLUE: OLS is no longer <em>best</em>, and GLS is now <em>best</em>.) In practice, this efficiency should translate to more power/smaller standard errors.</p>
<p>Let’s check out a special case of GLS: weighted least squares (WLS).</p>
</div>
<div id="wls" class="section level2">
<h2>WLS</h2>
<p>Let’s impose a bit of structure on our <span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span> matrix (the variance-covariance matrix of our disturbances). In particular, assume the disturbances are independent. This assumption implies the off-diagonal elements of <span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span> are zeros (in other words: <span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span> is diagonal). Now let <span class="math inline">\(\omega_i(\mathbf{X})\)</span> denote the <span class="math inline">\(i\)</span><sup>th</sup> diagonal element of <span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span>. Then</p>
<p><span class="math display">\[ \mathop{\boldsymbol{E}}\left[ \boldsymbol{\varepsilon} \boldsymbol{\varepsilon}^\prime | \mathbf{X} \right] = \sigma^2 \boldsymbol{\Omega}(\mathbf{X}) = \sigma^2 \mathop{\text{diag}}\left\{ \omega_i(\mathbf{X})\right\} \]</span></p>
<p>or</p>
<p><span class="math display">\[ \mathop{\boldsymbol{E}}\left[ \varepsilon_i^2 \right] = \sigma^2\omega_i(\mathbf{X}) \]</span></p>
<p>Think about the diagonal matrix and the GLW/WLS estimator. What is WLS doing? It is just <em>weighting</em> each observation by</p>
<p><span class="math display">\[ w_i = \dfrac{1}{\sqrt{\omega_i (\mathbf{X})}} \]</span></p>
<p>and then running OLS (on the weighted dataset) to recover the weighted least squares (WLS) estimator. In other words, we make two transformations</p>
<p><span class="math display">\[\tilde{y}_i = \dfrac{y_i}{\sqrt{\omega_i(\mathbf{X})}} \quad \text{and} \quad
\tilde{x}_i = \dfrac{x_i}{\sqrt{\omega_i(\mathbf{X})}}\]</span></p>
<p>and then regress <span class="math inline">\(\tilde{y_i}\)</span> on <span class="math inline">\(\tilde{x_i}\)</span>.</p>
<p>To see these steps a bit more formally:</p>
<span class="math display">\[\begin{align} \mathbf{b}_\text{gls}
  &amp;=
  \left(\mathbf{X}^{\prime}\boldsymbol{\Omega}^{-1}\mathbf{X}\right)^{-1}\mathbf{X}^{\prime}\boldsymbol{\Omega}^{-1}\mathbf{y}
  \\&amp;=
  \left(\mathbf{X}^{\prime}\mathbf{W}\mathbf{X}\right)^{-1}\mathbf{X}^{\prime}\mathbf{W}\mathbf{y}
  \\&amp;=
  \left(\mathbf{X}^{\prime}\mathbf{C}^{\prime}\mathbf{C}\mathbf{X}\right)^{-1}\mathbf{X}^{\prime}\mathbf{C}^{\prime}\mathbf{C}\mathbf{y}
  \\&amp;=
  \left((\mathbf{C}\mathbf{X})^{\prime}\mathbf{C}\mathbf{X}\right)^{-1}(\mathbf{C}\mathbf{X})^{\prime}\mathbf{C}\mathbf{y}
  \\&amp;=
  \left(\widetilde{\mathbf{X}}^{\prime}\widetilde{\mathbf{X}}\right)^{-1}\widetilde{\mathbf{X}}^{\prime}\widetilde{\mathbf{y}}  
\end{align}\]</span>
</div>
<div id="wls-simulation" class="section level2">
<h2>WLS simulation</h2>
<p>Let’s write a simulation in R that can compare OLS and WLS via their coefficient estimates and their efficiency. What do we need to do for this simulation?</p>
<ol style="list-style-type: decimal">
<li>Generate a population of data (whose data-generating process matches our assumptions).</li>
<li>Draw random samples from the population.</li>
<li>Estimate OLS and WLS for each sample.</li>
<li>Repeat.</li>
<li>Plot the distributions of coefficient estimates.</li>
<li>Compare the distributions via astute observation.</li>
</ol>
<p>First things first: my R setup</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Setup ----</span>
<span class="co"># Options</span>
<span class="kw">options</span>(<span class="dt">stringsAsFactors =</span> F)
<span class="co"># Packages</span>
<span class="kw">library</span>(dplyr)</code></pre></div>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(magrittr)
<span class="kw">library</span>(parallel)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(ggthemes)
<span class="kw">library</span>(viridis)
<span class="kw">library</span>(lfe)</code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Directory</span>
<span class="kw">setwd</span>(<span class="st">&quot;/Users/edwardarubin/Dropbox/Teaching/ARE212/Section07&quot;</span>)
<span class="co"># My ggplot2 theme</span>
theme_ed &lt;-<span class="st"> </span><span class="kw">theme</span>(
  <span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>,
  <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="ot">NA</span>),
  <span class="dt">panel.border =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="ot">NA</span>, <span class="dt">color =</span> <span class="st">&quot;grey75&quot;</span>),
  <span class="dt">axis.ticks =</span> <span class="kw">element_line</span>(<span class="dt">color =</span> <span class="st">&quot;grey85&quot;</span>),
  <span class="dt">panel.grid.major =</span> <span class="kw">element_line</span>(<span class="dt">color =</span> <span class="st">&quot;grey95&quot;</span>, <span class="dt">size =</span> <span class="fl">0.2</span>),
  <span class="dt">panel.grid.minor =</span> <span class="kw">element_line</span>(<span class="dt">color =</span> <span class="st">&quot;grey95&quot;</span>, <span class="dt">size =</span> <span class="fl">0.2</span>),
  <span class="dt">legend.key =</span> <span class="kw">element_blank</span>())</code></pre></div>
<p>Second things second: let’s write a few functions that will be useful in this simulation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Functions ----</span>
<span class="co"># Function to convert tibble, data.frame, or tbl_df to matrix</span>
to_matrix &lt;-<span class="st"> </span>function(the_df, vars) {
  <span class="co"># Create a matrix from variables in var</span>
  new_mat &lt;-<span class="st"> </span>the_df %&gt;%
<span class="st">    </span><span class="co"># Select the columns given in &#39;vars&#39;</span>
<span class="st">    </span><span class="kw">select_</span>(<span class="dt">.dots =</span> vars) %&gt;%
<span class="st">    </span><span class="co"># Convert to matrix</span>
<span class="st">    </span><span class="kw">as.matrix</span>()
  <span class="co"># Return &#39;new_mat&#39;</span>
  <span class="kw">return</span>(new_mat)
}
<span class="co"># Function for OLS coefficient estimates</span>
b_ols &lt;-<span class="st"> </span>function(y, X) {
  <span class="co"># Calculate beta hat</span>
  beta_hat &lt;-<span class="st"> </span><span class="kw">solve</span>(<span class="kw">t</span>(X) %*%<span class="st"> </span>X) %*%<span class="st"> </span><span class="kw">t</span>(X) %*%<span class="st"> </span>y
  <span class="co"># Return beta_hat</span>
  <span class="kw">return</span>(beta_hat)
}</code></pre></div>
<p>We will use the same data-generating process (DGP) that Max used in his notes:</p>
<ul>
<li><span class="math inline">\(x \sim \text{Uniform}(0,\, 2000)\)</span></li>
<li><span class="math inline">\(\varepsilon \sim \mathop{N}\left(0,\, 400 \cdot \frac{1}{100}x^2\right)\)</span></li>
<li><span class="math inline">\(\alpha = 0.5\)</span></li>
<li><span class="math inline">\(\beta = 1.5\)</span></li>
</ul>
<p>Notice that this setup implicitly defines <span class="math inline">\(\sigma^2 = 400\)</span> and <span class="math inline">\(\omega_i = \frac{1}{100}x_i^2\)</span>.</p>
<p>Let’s now create our population.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set the seed</span>
<span class="kw">set.seed</span>(<span class="dv">12345</span>)
<span class="co"># Set population size, N</span>
N &lt;-<span class="st"> </span><span class="fl">1e5</span>
<span class="co"># Set alpha and beta</span>
alpha &lt;-<span class="st"> </span><span class="fl">0.5</span>
beta &lt;-<span class="st"> </span><span class="fl">1.5</span>
<span class="co"># Create the population data: intercept (i) and X</span>
pop_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">i =</span> <span class="dv">1</span>,
  <span class="dt">x =</span> <span class="kw">runif</span>(<span class="dt">n =</span> N, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">2000</span>)
  ) %&gt;%<span class="st"> </span><span class="kw">tbl_df</span>()
<span class="co"># Generate error term, e</span>
pop_df %&lt;&gt;%<span class="st"> </span><span class="kw">mutate</span>(
  <span class="dt">e =</span> <span class="kw">rnorm</span>(N, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="kw">sqrt</span>(<span class="dv">4</span> *<span class="st"> </span>x^<span class="dv">2</span>)))
<span class="co"># Calculate y</span>
pop_df %&lt;&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">y =</span> alpha +<span class="st"> </span><span class="fl">1.5</span> *<span class="st"> </span>x +<span class="st"> </span>e)</code></pre></div>
<p>Let’s also add the weights that we discussed previously, <em>i.e.</em>,</p>
<p><span class="math display">\[ w_i = \dfrac{1}{\sqrt{\omega_i (\mathbf{X})}} = \dfrac{10}{x} \]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Add weights</span>
pop_df %&lt;&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">w =</span> <span class="dv">10</span>/x)</code></pre></div>
<p>We should also apply the weights.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pop_df %&lt;&gt;%<span class="st"> </span><span class="kw">mutate</span>(
  <span class="dt">y_w =</span> y *<span class="st"> </span>w,
  <span class="dt">i_w =</span> i *<span class="st"> </span>w,
  <span class="dt">x_w =</span> x *<span class="st"> </span>w)</code></pre></div>
<p>Notice that we apply the weights to the entire observation—including the intercept (think of it as multiply both <span class="math inline">\(\mathbf{y}\)</span> and <span class="math inline">\(\mathbf{X}\)</span> by a weighting matrix).</p>
<p>Now we want to write a function that takes care of a single iteration of the simulation. This function needs to draw a sample of size 1,000 and then estimate/return the OLS and WLS coefficients.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Function for a single iteration of the simulation</span>
one_run &lt;-<span class="st"> </span>function(iter, population) {
  <span class="co"># Sample 1000 rows from the population</span>
  sample_df &lt;-<span class="st"> </span><span class="kw">sample_n</span>(<span class="dt">tbl =</span> population, <span class="dt">size =</span> <span class="dv">1000</span>)
  <span class="co"># Calculate the OLS coef. (using unweighted variables)</span>
  coef_ols &lt;-<span class="st"> </span><span class="kw">b_ols</span>(
    <span class="dt">y =</span> <span class="kw">to_matrix</span>(sample_df, <span class="st">&quot;y&quot;</span>),
    <span class="dt">X =</span> <span class="kw">to_matrix</span>(sample_df, <span class="kw">c</span>(<span class="st">&quot;i&quot;</span>, <span class="st">&quot;x&quot;</span>)))
  <span class="co"># Calculate the WLS coef. (using weighted variables)</span>
  coef_wls &lt;-<span class="st"> </span><span class="kw">b_ols</span>(
    <span class="dt">y =</span> <span class="kw">to_matrix</span>(sample_df, <span class="st">&quot;y_w&quot;</span>),
    <span class="dt">X =</span> <span class="kw">to_matrix</span>(sample_df, <span class="kw">c</span>(<span class="st">&quot;i_w&quot;</span>, <span class="st">&quot;x_w&quot;</span>)))
  <span class="co"># Create a data.frame to return</span>
  coef_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
    <span class="dt">est    =</span> <span class="kw">as.vector</span>(<span class="kw">c</span>(coef_ols, coef_wls)),
    <span class="dt">param  =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;int&quot;</span>, <span class="st">&quot;coef&quot;</span>), <span class="dv">2</span>),
    <span class="dt">method =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;ols&quot;</span>, <span class="st">&quot;wls&quot;</span>), <span class="dt">each =</span> <span class="dv">2</span>),
    <span class="dt">iter   =</span> iter
    )
  <span class="co"># Return the data.frame</span>
  <span class="kw">return</span>(coef_df)
}</code></pre></div>
<p>Finally, we want to run the simulation 10,000 times. I’m going to parallelize to speed things up. You can skip this part, if you would like, but you may want to reduce the number of iterations that you run.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make the cluster</span>
cl &lt;-<span class="st"> </span><span class="kw">makeCluster</span>(<span class="dv">4</span>)
<span class="co"># Load functions on the cluster</span>
<span class="kw">clusterEvalQ</span>(cl, {
  <span class="kw">library</span>(dplyr)
  <span class="kw">library</span>(magrittr)
  })
<span class="co"># Export our data and functions to the cluster</span>
<span class="kw">clusterExport</span>(cl, <span class="st">&quot;pop_df&quot;</span>)
<span class="kw">clusterExport</span>(cl, <span class="kw">c</span>(<span class="st">&quot;to_matrix&quot;</span>, <span class="st">&quot;b_ols&quot;</span>, <span class="st">&quot;one_run&quot;</span>))
<span class="co"># Set seed in parallel</span>
<span class="kw">clusterSetRNGStream</span>(cl, <span class="dv">12345</span>)</code></pre></div>
<p>Now run the <code>one_run()</code> function several (10,000) times.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim_df &lt;-<span class="st"> </span><span class="kw">parLapply</span>(
  <span class="dt">cl =</span> cl,
  <span class="dt">X =</span> <span class="dv">1</span>:<span class="fl">1e4</span>,
  <span class="dt">fun =</span> one_run,
  <span class="dt">population =</span> pop_df) %&gt;%<span class="st"> </span><span class="kw">bind_rows</span>() %&gt;%<span class="st"> </span><span class="kw">tbl_df</span>()</code></pre></div>
<p>Finally, stop the cluster.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Stop the cluster</span>
<span class="kw">stopCluster</span>(cl)</code></pre></div>
<p>If you are opting for the non-parallelized version:<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim_df &lt;-<span class="st"> </span><span class="kw">lapply</span>(
  <span class="dt">X =</span> <span class="dv">1</span>:<span class="fl">1e4</span>,
  <span class="dt">FUN =</span> one_run,
  <span class="dt">population =</span> pop_df) %&gt;%<span class="st"> </span><span class="kw">bind_rows</span>() %&gt;%<span class="st"> </span><span class="kw">tbl_df</span>()</code></pre></div>
<p>Let’s check out the distributions of estimates for <span class="math inline">\(\beta\)</span>. For a task like this one, I like <code>ggplot2</code>’s <code>geom_density()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">filter</span>(sim_df, param ==<span class="st"> &quot;coef&quot;</span>), <span class="kw">aes</span>(<span class="dt">x =</span> est)) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">1.5</span>, <span class="dt">color =</span> <span class="st">&quot;grey70&quot;</span>, <span class="dt">size =</span> <span class="fl">0.75</span>) +
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> method, <span class="dt">color =</span> method), <span class="dt">alpha =</span> <span class="fl">0.7</span>) +
<span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Estimate for &quot;</span>, beta))) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Density&quot;</span>) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Simulation comparing coefficients from OLS and WLS&quot;</span>) +
<span class="st">  </span><span class="kw">scale_fill_viridis</span>(<span class="st">&quot;Method&quot;</span>, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;OLS&quot;</span>, <span class="st">&quot;WLS&quot;</span>),
    <span class="dt">discrete =</span> T, <span class="dt">end =</span> <span class="fl">0.95</span>) +
<span class="st">  </span><span class="kw">scale_color_viridis</span>(<span class="st">&quot;Method&quot;</span>, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;OLS&quot;</span>, <span class="st">&quot;WLS&quot;</span>),
    <span class="dt">discrete =</span> T, <span class="dt">end =</span> <span class="fl">0.95</span>) +
<span class="st">  </span>theme_ed</code></pre></div>
<p><img src="section07_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>What do we see? Exactly what Max told us we would see (and showed us): both OLS and WLS are unbiased (both distributions are centered on the true parameter), but when we know <span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span>, WLS (a special case of GLS) is more efficient—the distribution of estimates is tighter around the true value of the parameter.</p>
<p>And for a numeric summarization of the results:<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim_df %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(param, method) %&gt;%
<span class="st">  </span><span class="kw">summarize</span>(<span class="kw">mean</span>(est), <span class="kw">sd</span>(est)) %&gt;%
<span class="st">  </span>knitr::<span class="kw">kable</span>(<span class="dt">digits =</span> <span class="dv">4</span>,
    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;Parameter&quot;</span>, <span class="st">&quot;Method&quot;</span>, <span class="st">&quot;Mean&quot;</span>, <span class="st">&quot;Std. Dev.&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Method</th>
<th align="right">Mean</th>
<th align="right">Std. Dev.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">coef</td>
<td align="left">ols</td>
<td align="right">1.5061</td>
<td align="right">0.1383</td>
</tr>
<tr class="even">
<td align="left">coef</td>
<td align="left">wls</td>
<td align="right">1.5013</td>
<td align="right">0.0637</td>
</tr>
<tr class="odd">
<td align="left">int</td>
<td align="left">ols</td>
<td align="right">-1.5054</td>
<td align="right">92.6954</td>
</tr>
<tr class="even">
<td align="left">int</td>
<td align="left">wls</td>
<td align="right">0.0021</td>
<td align="right">3.4135</td>
</tr>
</tbody>
</table>
<p><strong>Question</strong>: If GLS is so efficient, why don’t more people use it?</p>
<p><strong>Answer</strong>: It is pretty rare to know the exact function that generates the heteroskedasticity in our disturbances.</p>
<p><strong>Question</strong>: What if we do not get <span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span> get exactly right, but we at least specify something? Is something better than nothing?</p>
<p><strong>Answer</strong>: Let’s simulate it.</p>
</div>
<div id="misspecified-wls-simulation" class="section level2">
<h2>Misspecified WLS simulation</h2>
<p>We will stick with the same population as above, but now, we will mis-specify the weights. Specifically, instead of using the (correct) weights <span class="math inline">\(w_i = \frac{10}{x_i}\)</span>, we will use the (incorrect) weights <span class="math inline">\(v_i = \frac{10}{x^2}\)</span>.</p>
<p>Let’s add the <span class="math inline">\(v_i\)</span> weights to the population dataset and then apply them to our observations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Add the bad weights</span>
pop_df %&lt;&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">v =</span> <span class="dv">10</span>/x^<span class="dv">2</span>)
<span class="co"># Weight the observations with the bad weights</span>
pop_df %&lt;&gt;%<span class="st"> </span><span class="kw">mutate</span>(
  <span class="dt">y_v =</span> y *<span class="st"> </span>v,
  <span class="dt">i_v =</span> i *<span class="st"> </span>v,
  <span class="dt">x_v =</span> x *<span class="st"> </span>v)</code></pre></div>
<p>Next, we need to update our <code>one_run()</code> function to produce estimates using these new (bad) weights.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Function for a single iteration of the simulation</span>
one_run &lt;-<span class="st"> </span>function(iter, population) {
  <span class="co"># Sample 1000 rows from the population</span>
  sample_df &lt;-<span class="st"> </span><span class="kw">sample_n</span>(<span class="dt">tbl =</span> population, <span class="dt">size =</span> <span class="dv">1000</span>)
  <span class="co"># Calculate the OLS coef. (using unweighted variables)</span>
  coef_ols &lt;-<span class="st"> </span><span class="kw">b_ols</span>(
    <span class="dt">y =</span> <span class="kw">to_matrix</span>(sample_df, <span class="st">&quot;y&quot;</span>),
    <span class="dt">X =</span> <span class="kw">to_matrix</span>(sample_df, <span class="kw">c</span>(<span class="st">&quot;i&quot;</span>, <span class="st">&quot;x&quot;</span>)))
  <span class="co"># Calculate the WLS coef. (using correctly weighted variables)</span>
  coef_wls &lt;-<span class="st"> </span><span class="kw">b_ols</span>(
    <span class="dt">y =</span> <span class="kw">to_matrix</span>(sample_df, <span class="st">&quot;y_w&quot;</span>),
    <span class="dt">X =</span> <span class="kw">to_matrix</span>(sample_df, <span class="kw">c</span>(<span class="st">&quot;i_w&quot;</span>, <span class="st">&quot;x_w&quot;</span>)))
  <span class="co"># Calculate the WLS coef. (using incorrectly weighted variables)</span>
  coef_wls_bad &lt;-<span class="st"> </span><span class="kw">b_ols</span>(
    <span class="dt">y =</span> <span class="kw">to_matrix</span>(sample_df, <span class="st">&quot;y_v&quot;</span>),
    <span class="dt">X =</span> <span class="kw">to_matrix</span>(sample_df, <span class="kw">c</span>(<span class="st">&quot;i_v&quot;</span>, <span class="st">&quot;x_v&quot;</span>)))
  <span class="co"># Create a data.frame to return</span>
  coef_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
    <span class="dt">est    =</span> <span class="kw">as.vector</span>(<span class="kw">c</span>(coef_ols, coef_wls, coef_wls_bad)),
    <span class="dt">param  =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;int&quot;</span>, <span class="st">&quot;coef&quot;</span>), <span class="dv">3</span>),
    <span class="dt">method =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;ols&quot;</span>, <span class="st">&quot;wls&quot;</span>, <span class="st">&quot;wls bad&quot;</span>), <span class="dt">each =</span> <span class="dv">2</span>),
    <span class="dt">iter   =</span> iter
    )
  <span class="co"># Return the data.frame</span>
  <span class="kw">return</span>(coef_df)
}</code></pre></div>
<p>We’re ready to run the simulation again.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make the cluster</span>
cl &lt;-<span class="st"> </span><span class="kw">makeCluster</span>(<span class="dv">4</span>)
<span class="co"># Load functions on the cluster</span>
<span class="kw">clusterEvalQ</span>(cl, {
  <span class="kw">library</span>(dplyr)
  <span class="kw">library</span>(magrittr)
  })
<span class="co"># Export our data and functions to the cluster</span>
<span class="kw">clusterExport</span>(cl, <span class="st">&quot;pop_df&quot;</span>)
<span class="kw">clusterExport</span>(cl, <span class="kw">c</span>(<span class="st">&quot;to_matrix&quot;</span>, <span class="st">&quot;b_ols&quot;</span>, <span class="st">&quot;one_run&quot;</span>))
<span class="co"># Set seed in parallel</span>
<span class="kw">clusterSetRNGStream</span>(cl, <span class="dv">12345</span>)
<span class="co"># Run the simulation 10,000 times</span>
miss_df &lt;-<span class="st"> </span><span class="kw">parLapply</span>(
  <span class="dt">cl =</span> cl,
  <span class="dt">X =</span> <span class="dv">1</span>:<span class="fl">1e4</span>,
  <span class="dt">fun =</span> one_run,
  <span class="dt">population =</span> pop_df) %&gt;%<span class="st"> </span><span class="kw">bind_rows</span>() %&gt;%<span class="st"> </span><span class="kw">tbl_df</span>()
<span class="co"># Stop the cluster</span>
<span class="kw">stopCluster</span>(cl)</code></pre></div>
<p>If you are not parallelizing:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Run the simulation 10,000 times</span>
miss_df &lt;-<span class="st"> </span><span class="kw">lapply</span>(
  <span class="dt">X =</span> <span class="dv">1</span>:<span class="fl">1e4</span>,
  <span class="dt">FUN =</span> one_run,
  <span class="dt">population =</span> pop_df) %&gt;%<span class="st"> </span><span class="kw">bind_rows</span>() %&gt;%<span class="st"> </span><span class="kw">tbl_df</span>()</code></pre></div>
<p>Plot the results for the estimates of <span class="math inline">\(\beta\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">filter</span>(miss_df, param ==<span class="st"> &quot;coef&quot;</span>), <span class="kw">aes</span>(<span class="dt">x =</span> est)) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">1.5</span>, <span class="dt">color =</span> <span class="st">&quot;grey70&quot;</span>, <span class="dt">size =</span> <span class="fl">0.75</span>) +
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> method, <span class="dt">color =</span> method), <span class="dt">alpha =</span> <span class="fl">0.7</span>) +
<span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Estimate for &quot;</span>, beta))) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Density&quot;</span>) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Simulation comparing coefficients from OLS and WLS&quot;</span>,
    <span class="dt">subtitle =</span> <span class="st">&quot;Allowing for misspecification in WLS&quot;</span>) +
<span class="st">  </span><span class="kw">scale_fill_viridis</span>(<span class="st">&quot;Method&quot;</span>,
    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;OLS&quot;</span>, <span class="st">&quot;WLS&quot;</span>, <span class="st">&quot;WLS misspecified&quot;</span>),
    <span class="dt">discrete =</span> T, <span class="dt">end =</span> <span class="fl">0.95</span>, <span class="dt">direction =</span> -<span class="dv">1</span>) +
<span class="st">  </span><span class="kw">scale_color_viridis</span>(<span class="st">&quot;Method&quot;</span>,
    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;OLS&quot;</span>, <span class="st">&quot;WLS&quot;</span>, <span class="st">&quot;WLS misspecified&quot;</span>),
    <span class="dt">discrete =</span> T, <span class="dt">end =</span> <span class="fl">0.95</span>, <span class="dt">direction =</span> -<span class="dv">1</span>) +
<span class="st">  </span>theme_ed</code></pre></div>
<p><img src="section07_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Hmmm… it is not looking good for WLS (GLS) when we mis-specify the weights (<span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span>). But it is a bit difficult to really see what’s going on. Let’s zoom in a bit (adding the <code>xlim()</code> function to our <code>ggplot()</code> allows us to control the <span class="math inline">\(x\)</span>-axis limits).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">filter</span>(miss_df, param ==<span class="st"> &quot;coef&quot;</span>), <span class="kw">aes</span>(<span class="dt">x =</span> est)) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">1.5</span>, <span class="dt">color =</span> <span class="st">&quot;grey70&quot;</span>, <span class="dt">size =</span> <span class="fl">0.75</span>) +
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> method, <span class="dt">color =</span> method), <span class="dt">alpha =</span> <span class="fl">0.65</span>) +
<span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Estimate for &quot;</span>, beta))) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Density&quot;</span>) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Simulation comparing coefficients from OLS and WLS&quot;</span>,
    <span class="dt">subtitle =</span> <span class="st">&quot;Allowing for misspecification in WLS&quot;</span>) +
<span class="st">  </span><span class="kw">xlim</span>(<span class="fl">1.5</span> +<span class="st"> </span><span class="kw">c</span>(-<span class="dv">1</span>,<span class="dv">1</span>) *<span class="st"> </span><span class="dv">2</span>) +
<span class="st">  </span><span class="kw">scale_fill_viridis</span>(<span class="st">&quot;Method&quot;</span>,
    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;OLS&quot;</span>, <span class="st">&quot;WLS&quot;</span>, <span class="st">&quot;WLS misspecified&quot;</span>),
    <span class="dt">discrete =</span> T, <span class="dt">end =</span> <span class="fl">0.95</span>, <span class="dt">direction =</span> -<span class="dv">1</span>) +
<span class="st">  </span><span class="kw">scale_color_viridis</span>(<span class="st">&quot;Method&quot;</span>,
    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;OLS&quot;</span>, <span class="st">&quot;WLS&quot;</span>, <span class="st">&quot;WLS misspecified&quot;</span>),
    <span class="dt">discrete =</span> T, <span class="dt">end =</span> <span class="fl">0.95</span>, <span class="dt">direction =</span> -<span class="dv">1</span>) +
<span class="st">  </span>theme_ed</code></pre></div>
<pre><code>## Warning: Removed 1290 rows containing non-finite values (stat_density).</code></pre>
<p><img src="section07_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>In numbers:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">miss_df %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(param, method) %&gt;%
<span class="st">  </span><span class="kw">summarize</span>(<span class="kw">mean</span>(est), <span class="kw">sd</span>(est)) %&gt;%
<span class="st">  </span>knitr::<span class="kw">kable</span>(<span class="dt">digits =</span> <span class="dv">4</span>,
    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;Parameter&quot;</span>, <span class="st">&quot;Method&quot;</span>, <span class="st">&quot;Mean&quot;</span>, <span class="st">&quot;Std. Dev.&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Method</th>
<th align="right">Mean</th>
<th align="right">Std. Dev.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">coef</td>
<td align="left">ols</td>
<td align="right">1.5061</td>
<td align="right">0.1383</td>
</tr>
<tr class="even">
<td align="left">coef</td>
<td align="left">wls</td>
<td align="right">1.5013</td>
<td align="right">0.0637</td>
</tr>
<tr class="odd">
<td align="left">coef</td>
<td align="left">wls bad</td>
<td align="right">1.3457</td>
<td align="right">1.4279</td>
</tr>
<tr class="even">
<td align="left">int</td>
<td align="left">ols</td>
<td align="right">-1.5054</td>
<td align="right">92.6954</td>
</tr>
<tr class="odd">
<td align="left">int</td>
<td align="left">wls</td>
<td align="right">0.0021</td>
<td align="right">3.4135</td>
</tr>
<tr class="even">
<td align="left">int</td>
<td align="left">wls bad</td>
<td align="right">0.5225</td>
<td align="right">6.2608</td>
</tr>
</tbody>
</table>
<p>Not so good. While GLS/WLS provide us with greater efficiency in estimators <strong>when we know</strong> <span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span>, this knowledge of <span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span> is an enormous assumption. Furthermore, when we are incorrect about this assumption—<em>i.e.</em>, when we think we know <span class="math inline">\(\boldsymbol{\Omega}(\mathbf{X})\)</span> but in reality do not—GLS/WLS becomes very inefficient.</p>
<p>To takeaways from these simulations:</p>
<ol style="list-style-type: decimal">
<li>Humility in econometrics (and in life) is a great virtue: don’t assume you know everything and don’t hide your assumptions.</li>
<li>You will generally not use GLS in real life. One common exception: you may use WLS when you know the sample weights in your sample or to adjust for heterogeneous treatment effects. You may also use some forms of feasible GLS (FGLS).<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></li>
</ol>
</div>
<div id="canned-weighting" class="section level2">
<h2>Canned weighting</h2>
<p>As you may guess, our favorite canned regression function (<code>felm()</code>) allows you to apply weights and run WLS. You just need to feed the <code>weights</code> argument a set of weights, and you are (almost) ready to go. First, check the documentation of <code>felm()</code> (<code>?felm</code>): the <code>weights</code> that <code>felm()</code> wants are the weights that minimize <code>sum(w*e^2)</code>, <em>i.e.</em>, the square of the weights we used above.</p>
<p>What is the difference between the weights? The weights we used above are the weights along the diagonal matrix <span class="math inline">\(\mathbf{C}\)</span> that transform <span class="math inline">\(y\)</span> and <span class="math inline">\(\mathbf{X}\)</span>. <code>felm()</code> wants the weights on the diagonal of <span class="math inline">\(\mathbf{W}\)</span>, which we previously defined as <span class="math inline">\(\mathbf{W} = \mathbf{C}^{\prime}\mathbf{C}\)</span>.</p>
<p>We will calculate the weighted least squares estimates four different ways.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 1. &#39;felm&#39; with our squared weights</span>
<span class="kw">felm</span>(y ~<span class="st"> </span>x, <span class="dt">data =</span> pop_df, <span class="dt">weights =</span> pop_df$w^<span class="dv">2</span>)</code></pre></div>
<pre><code>## (Intercept)           x 
##      0.4777      1.4999</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 2. &#39;felm&#39;, re-defining our weights</span>
<span class="kw">felm</span>(y ~<span class="st"> </span>x, <span class="dt">data =</span> pop_df, <span class="dt">weights =</span> (<span class="dv">10</span>/pop_df$x)^<span class="dv">2</span>)</code></pre></div>
<pre><code>## (Intercept)           x 
##      0.4777      1.4999</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 3. &#39;felm&#39; with our transformed variables</span>
<span class="kw">felm</span>(y_w ~<span class="st"> </span>-<span class="dv">1</span> +<span class="st"> </span>i_w +<span class="st"> </span>x_w, <span class="dt">data =</span> pop_df)</code></pre></div>
<pre><code>##    i_w    x_w 
## 0.4777 1.4999</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 4. Using our &#39;b_ols&#39; function on the transformed variables</span>
<span class="co"># (As we did in the simulation)</span>
<span class="kw">b_ols</span>(<span class="dt">y =</span> <span class="kw">to_matrix</span>(pop_df, <span class="st">&quot;y_w&quot;</span>),
  <span class="dt">X =</span> <span class="kw">to_matrix</span>(pop_df, <span class="kw">c</span>(<span class="st">&quot;i_w&quot;</span>, <span class="st">&quot;x_w&quot;</span>)))</code></pre></div>
<pre><code>##           y_w
## i_w 0.4776918
## x_w 1.4998995</code></pre>
<p>Great! Now you can impress all of your friends with weighted regressions.</p>
</div>
</div>
<div id="survey" class="section level1">
<h1>Survey</h1>
<p>If you can spare a minute, please fill out the following survey to help me better understand how section/learning R is going. Thank you in advance!</p>
<p><a href="https://edrubin.typeform.com/to/BcECl6">Launch the survey!</a></p>
</div>
<div id="fun-tools-atom" class="section level1">
<h1>Fun tools: Atom</h1>
<p>As advertised above, henceforth I will try to include a new section in the notes about tools that I have found useful for research in applied economics (or in the life of a graduate student).</p>
<p>This week, I would like to introduce you to the app. in which I probably spend 99% of my work/research time: <a href="https://atom.io">Atom</a>.<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> Atom is an amazingly useful and infinitely customizable test editor produced by the folks at Github.</p>
<p>What do I do with Atom? Essentially everything. Atom has beautiful syntax highlighting for essentially any language you can imagine—R, Stata, Python, Julia, LaTeX, Markdown, C++, …. You can also link Atom to other apps, so you are not stuck copying and pasting. I actually use RStudio pretty infrequently—instead, I connect Atom to my terminal (and run R in my terminal… there is an <a href="https://atom.io/packages/r-exec">Atom package that helps you with this task</a>). And I <a href="https://atom.io/packages/latextools">edit and compile LaTeX documents from Atom</a>.</p>
<p>Okay, so you see that you can do lots of things in Atom, but why would you want to? Well, in addition to being beautiful and <em>really, really</em> customizable, Atom has a few features that most other text editors lack. My favorite: multiple cursors based upon word searching:</p>
<div class="figure">
<img src="Images/multiCursors.gif" alt="Multiple cursors in action." />
<p class="caption">Multiple cursors in action.</p>
</div>
<p>RStudio recently added multiple-cursor capabilities, but RStudio’s multiple cursors are still nowhere near what Atom offers. For instance, check this out:<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a></p>
<div class="figure">
<img src="Images/sequentialNumber.gif" alt="Multiple cursors with customizable sequences of numbers!" />
<p class="caption">Multiple cursors with customizable sequences of numbers!</p>
</div>
<p>Boom! If I had only known about Atom sooner….</p>
<p>Two other Atom features that I find hugely useful/productivity-enhancing are customizable keyboard shortcuts, snippets, and Github syncing. I’ll let you explore these features on your own.</p>
<p>Anyway, Atom can help you with a lot of text editing tasks. And it’s <a href="https://atom.io/themes/duotone-dark-sea-syntax">pretty</a>.</p>
<div class="figure">
<img src="Images/myAtom.png" alt="My Atom right now." />
<p class="caption">My Atom right now.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Don’t worry: I’m not being paid to endorse any of these products.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>smallest variance<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Phew!<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>See Max’s notes.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>To make our simulation as efficient as possible, I am keeping the things I do within a single iteration very simple. I also do as much as possible <em>outside</em> the individual iterations, <em>e.g.</em>, creating the population data.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Again, if you are not going to run the simulation in parallel, you may want to run fewer than 10,000 iterations.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>I use a few new functions below. <code>group_by()</code> allows us to specify by which variables we would like to group our data (helpful for <code>summarize()</code> and <code>mutate()</code>). <code>kable()</code> is a function from the <code>knitr</code> package that outputs simple tables (the default format is Markdown).<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>If these exceptions do not make sense, don’t worry. You will see them in later classes.<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Sublime Text is very similar alternative to Atom. I started out with Sublime Text, but its updates became really infrequent. Sublime Text technically costs money and is run by a small group of people. Atom is free and backed by an organization I expect to be around for a while. Sublime Text is great; I’m just sticking with Atom.<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>This functionality requires the Atom package <a href="https://atom.io/packages/sequential-number">sequential-number</a>.<a href="#fnref10">↩</a></p></li>
</ol>
</div>

<!-- <?php include_once("analyticstracking.php") ?> -->

<!-- For Google Analytics: -->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88887510-2', 'auto');
  ga('send', 'pageview');

</script>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
