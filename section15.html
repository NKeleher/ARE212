<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Section 15: Learning with machines</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ARE 212</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Section notes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="notes.html">Table of Contents</a>
    </li>
    <li>
      <a href="section00.html">Section 0</a>
    </li>
    <li>
      <a href="section01.html">Section 1</a>
    </li>
    <li>
      <a href="section02.html">Section 2</a>
    </li>
    <li>
      <a href="section03.html">Section 3</a>
    </li>
    <li>
      <a href="section04.html">Section 4</a>
    </li>
    <li>
      <a href="section05.html">Section 5</a>
    </li>
    <li>
      <a href="section06.html">Section 6</a>
    </li>
    <li>
      <a href="section07.html">Section 7</a>
    </li>
    <li>
      <a href="section08.html">Section 8</a>
    </li>
    <li>
      <a href="section09.html">Section 9</a>
    </li>
    <li>
      <a href="section10.html">Section 10</a>
    </li>
    <li>
      <a href="section11.html">Section 11</a>
    </li>
    <li>
      <a href="section12.html">Section 12</a>
    </li>
    <li>
      <a href="section13.html">Section 13</a>
    </li>
    <li>
      <a href="section14.html">Section 14</a>
    </li>
    <li>
      <a href="latexKnitr.html">LaTeX and knitr</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="Spring2017/notes.html">Spring 2017 Notes</a>
    </li>
  </ul>
</li>
<li>
  <a href="courseInfo.html">Course Info</a>
</li>
<li>
  <a href="syllabi.html">Syllabi</a>
</li>
<li>
  <a href="resources.html">R Resources</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="contact.html">
    <span class="fa fa-envelope-o fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/edrubin/ARE212">
    <span class="fa fa-github-square fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://edrub.in">
    <span class="fa fa-hand-peace-o fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Section 15: Learning with machines</h1>

</div>


<p><a href="Section15.zip"><span class="fa-stack fa-4x"> <i class="fa fa-folder fa-stack-2x"></i> <i class="fa fa-arrow-down fa-inverse fa-stack-1x"></i> </span></a></p>
<p><br></p>
<div id="admin" class="section level1">
<h1>Admin</h1>
<div id="announcements" class="section level2">
<h2>Announcements</h2>
<ul>
<li>Today is our last section! Thank you so much for a fantastic semester.</li>
<li>I’ve posted <a href="section14.html">another section</a> that covers simultaneous-equation models.</li>
</ul>
</div>
<div id="this-week" class="section level2">
<h2>This week</h2>
<p>Today we are going to take a very brief and general walk through the world of prediction, cross validation, and machine learning! These topics get their own classes, books, conferences, and careers, so there is no way that I am going to be able to teach you everything in less than 50 minutes. I am going to show you a few examples, introduce you to a couple of the bigger concepts, and then leave you hungry for more. You are at the greatest public university in the world and are here to learn. Go take a class in machine learning if these topics interest you at all—they are all over campus (Statistics, Computer Science, I School, Electrical Engineering, BIDS, just to name a few). There are some <a href="http://dlab.berkeley.edu/working-groups">working groups</a> too!</p>
</div>
<div id="two-books" class="section level2">
<h2>Two books</h2>
<p>Two of the most common books in the statistical learning are</p>
<ul>
<li><a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning with Applications in R</a></li>
<li><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</a></li>
</ul>
<p>And… both books have free PDFs available on their websites! Hurray for open science!</p>
</div>
<div id="what-you-will-need" class="section level2">
<h2>What you will need</h2>
<p>The <code>rpart</code> package!</p>
</div>
<div id="r-setup" class="section level2">
<h2>R setup</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># General R setup ----</span>
<span class="co"># Options</span>
<span class="kw">options</span>(<span class="dt">stringsAsFactors =</span> F)
<span class="co"># Pacman</span>
<span class="kw">library</span>(pacman)
<span class="co"># Load old packages</span>
<span class="kw">p_load</span>(readr, dplyr, ggplot2, ggthemes, parallel, magrittr, viridis)
<span class="co"># Load new packages</span>
<span class="kw">p_load</span>(rpart, rpart.plot, RColorBrewer)
<span class="co"># My ggplot2 theme</span>
theme_ed &lt;-<span class="st"> </span><span class="kw">theme</span>(
  <span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>,
  <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="ot">NA</span>),
  <span class="co"># panel.border = element_rect(fill = NA, color = &quot;grey75&quot;),</span>
  <span class="dt">axis.ticks =</span> <span class="kw">element_line</span>(<span class="dt">color =</span> <span class="st">&quot;grey95&quot;</span>, <span class="dt">size =</span> <span class="fl">0.3</span>),
  <span class="dt">panel.grid.major =</span> <span class="kw">element_line</span>(<span class="dt">color =</span> <span class="st">&quot;grey95&quot;</span>, <span class="dt">size =</span> <span class="fl">0.3</span>),
  <span class="dt">panel.grid.minor =</span> <span class="kw">element_line</span>(<span class="dt">color =</span> <span class="st">&quot;grey95&quot;</span>, <span class="dt">size =</span> <span class="fl">0.3</span>),
  <span class="dt">legend.key =</span> <span class="kw">element_blank</span>())
<span class="co"># My directories</span>
dir_15 &lt;-<span class="st"> &quot;/Users/edwardarubin/Dropbox/Teaching/ARE212/Section15/&quot;</span></code></pre></div>
</div>
</div>
<div id="motivations" class="section level1">
<h1>Motivations</h1>
<p>Up to this point, our class has almost exclusively focused on (causally) estimating parameters in linear models, <em>e.g.</em>, <span class="math display">\[\mathbf{y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}\]</span></p>
<p>As a result of this focus/objective, we have placed a tremendous level of importance on whether estimators are unbiased or consistent for the unknown parameters <span class="math inline">\(\boldsymbol{\beta}\)</span>. We also focused on linear estimators. In fact, when we were focusing on unbiased-ness, we exclusively restricted our search to the set of linear unbiased estimators.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> OLS and 2SLS performed quite well with this objective.</p>
<p>But what if we don’t actually care about <span class="math inline">\(\boldsymbol{\beta}\)</span>? What if we really want to be able to predict <span class="math inline">\(\mathbf{y}\)</span> (or extrapolating to outcomes for other, unobserved members of the population)? Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer have a <a href="https://www.aeaweb.org/articles?id=10.1257/aer.p20151023">nice article</a> entitled <em>Prediction Policy Problems</em> wherein they point out that these types of <em>prediction</em> problems may warrant tools other than those found in the classical econometrician’s toolbox. Why? Unbiasedness/consistency and inference don’t matter as much in the world of prediction. What matters? Low-error predictions! Enter: machine-learning/data-science/your-favorite-name-for-hot-new-data-prediction-tools.</p>
<p>Today we are going to peak at a few tools/methods for improving your <span class="math inline">\(\hat{\mathbf{y}}\)</span> rather than <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>. First we’ll talk about cross validation. Then we’ll talk about a few machine-learning algorithms.</p>
</div>
<div id="cross-validation" class="section level1">
<h1>Cross validation</h1>
<p>As you get more data, and as you shift your focus toward prediction (and away from research designs that warrant causality), overfitting becomes a huge issue. As we saw early in the class, as you give OLS more variables, it has access to more degrees of freedom, and thus OLS fits the data better and better. The problem here is that you are <strong>only</strong> getting a really good ‘fit’ (<em>e.g.</em>, high R<sup>2</sup>) <strong>for the data sample on which you are training the OLS model</strong>. If you took a second sample, you might find that all of the garbage variables that you threw into your OLS model actually hurt your prediction for the second sample.</p>
<p>That actually sounds like something we could easily demonstrate in R!</p>
<div id="dgp" class="section level2">
<h2>DGP</h2>
<p>Let’s generate a population of data through a simple linear relationship between <span class="math inline">\(y\)</span>, a constant, and <span class="math inline">\(x_1\)</span>. However, as is often the case in real life, there will be a hundred other variables at our disposal, all of which are just noise. In other words <span class="math display">\[ \mathbf{y} = \mathbf{3} + 7 \cdot \mathbf{x} + \boldsymbol{\varepsilon} \]</span></p>
<p>For this exercise:</p>
<ol style="list-style-type: decimal">
<li>Generate 2,000 observations with this DGP, where <span class="math inline">\(\varepsilon\)</span> and <span class="math inline">\(x\)</span> are both drawn from the standard normal distribution.</li>
<li>Generate 100 other variables <span class="math inline">\(\mathbf{Z}\)</span>. Standard normal distribution again.</li>
<li>Split the sample into two 1,000-member samples. Call these samples <span class="math inline">\(\mathbf{S}_1\)</span> and <span class="math inline">\(\mathbf{S}_2\)</span>.</li>
<li>Fit two competing models on <span class="math inline">\(\mathbf{S}_1\)</span>:
<ul>
<li><span class="math inline">\(\mathbf{y}\)</span> regressed on <span class="math inline">\(\mathbf{x}\)</span></li>
<li><span class="math inline">\(\mathbf{y}\)</span> regressed on <span class="math inline">\(\mathbf{x}\)</span> and the 100 noise variables of <span class="math inline">\(\mathbf{Z}\)</span></li>
</ul></li>
<li>Test how well the two competing models perform in predicting <span class="math inline">\(\mathbf{y}\)</span> in <span class="math inline">\(\mathbf{S}_2\)</span>.</li>
</ol>
</div>
<div id="model-fit" class="section level2">
<h2>Model fit</h2>
<p>Up to this point, we typically stuck with inferential statistics to (1) evaluate the <em>fit</em> of a model or (2) test competing models. However, because we not are currently focusing on estimating structural parameters and determining whether they differ significantly from zero, we need to shift how we evaluate models/fit.</p>
<p>There are many ways to evaluate models. Sometimes your application will help you determine which measure of model performance is best. For instance, if you really need to avoid false positives and are less concerned about false negatives, then you want a measure of model performance that really penalizes false positives.</p>
<p>For now, we are going to stick with three simple measures of model fit (that are particularly relevant for continuous/count outcome, as opposed to binary/categorical outcomes):</p>
<ol style="list-style-type: decimal">
<li>Mean absolute error <span class="math display">\[\text{MAE} = \dfrac{1}{N} \sum_{i = 1}^N \left|y_i - \hat{y}_i\right|\]</span></li>
<li>Mean squared error <span class="math display">\[\text{MSE} = \dfrac{1}{N} \sum_{i = 1}^N \left(y_i - \hat{y}_i\right)^2\]</span></li>
<li>Mean absolute percentage error <span class="math display">\[\text{MAPE} = \dfrac{1}{N} \sum_{i = 1}^N \left|\dfrac{y_i - \hat{y}_i}{y_i}\right|\]</span></li>
</ol>
</div>
<div id="overfitting-exercise" class="section level2">
<h2>Overfitting exercise</h2>
<p>First, we bake some data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The population size</span>
n &lt;-<span class="st"> </span><span class="fl">2e3</span>
<span class="co"># Set a seed</span>
<span class="kw">set.seed</span>(<span class="dv">12345</span>)
<span class="co"># Create the population</span>
s_df &lt;-<span class="st"> </span><span class="kw">data_frame</span>(
  <span class="dt">x =</span> <span class="kw">rnorm</span>(n),
  <span class="dt">j =</span> 1L,
  <span class="dt">e =</span> <span class="kw">rnorm</span>(n)
) %&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="dv">3</span> +<span class="st"> </span><span class="dv">7</span> *<span class="st"> </span>x +<span class="st"> </span>e)
<span class="co"># Create the 100 noise variables</span>
z_df &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data =</span> <span class="kw">rnorm</span>(n *<span class="st"> </span><span class="dv">100</span>), <span class="dt">nrow =</span> n) %&gt;%
<span class="st">  </span><span class="kw">as_data_frame</span>()
<span class="co"># Change the names of z_df</span>
<span class="kw">names</span>(z_df) &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;z&quot;</span>, <span class="dv">1</span>:<span class="dv">100</span>)
<span class="co"># Merge the datasets</span>
s_df &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">select</span>(s_df, -e), z_df)
<span class="co"># Split the datasets into two</span>
s1 &lt;-<span class="st"> </span>s_df[<span class="dv">1</span>:<span class="fl">1e3</span>,]
s2 &lt;-<span class="st"> </span>s_df[<span class="dv">1001</span>:<span class="fl">2e3</span>,]</code></pre></div>
<p>Now we train the two models (I’ll refer to them <em>a</em> and <em>b</em>) on <span class="math inline">\(\mathbf{S}_1\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The dependent variable from sample 1</span>
y1 &lt;-<span class="st"> </span>s1 %&gt;%<span class="st"> </span><span class="kw">select</span>(y) %&gt;%<span class="st"> </span><span class="kw">as.matrix</span>()
<span class="co"># Create the data matrices for each model</span>
X1_a &lt;-<span class="st"> </span>s1 %&gt;%<span class="st"> </span><span class="kw">select</span>(j, x) %&gt;%<span class="st"> </span><span class="kw">as.matrix</span>()
X1_b &lt;-<span class="st"> </span>s1 %&gt;%<span class="st"> </span><span class="kw">select</span>(j, x, <span class="kw">starts_with</span>(<span class="st">&quot;z&quot;</span>)) %&gt;%<span class="st"> </span><span class="kw">as.matrix</span>()
<span class="co"># Model 1: Regress y on x</span>
est_a &lt;-<span class="st"> </span><span class="kw">solve</span>(<span class="kw">crossprod</span>(X1_a)) %*%<span class="st"> </span><span class="kw">crossprod</span>(X1_a, y1)
est_b &lt;-<span class="st"> </span><span class="kw">solve</span>(<span class="kw">crossprod</span>(X1_b)) %*%<span class="st"> </span><span class="kw">crossprod</span>(X1_b, y1)</code></pre></div>
<p>And now we predict the outcome variable <span class="math inline">\(y\)</span> in sample <span class="math inline">\(\mathbf{S}_2\)</span> using the models we trained on <span class="math inline">\(\mathbf{S}_1\)</span> (<code>est_a</code> and <code>est_b</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The dependent variable from sample 2</span>
y2 &lt;-<span class="st"> </span>s2 %&gt;%<span class="st"> </span><span class="kw">select</span>(y) %&gt;%<span class="st"> </span><span class="kw">as.matrix</span>()
<span class="co"># Create the data matrices for each model for sample 2</span>
X2_a &lt;-<span class="st"> </span>s2 %&gt;%<span class="st"> </span><span class="kw">select</span>(j, x) %&gt;%<span class="st"> </span><span class="kw">as.matrix</span>()
X2_b &lt;-<span class="st"> </span>s2 %&gt;%<span class="st"> </span><span class="kw">select</span>(j, x, <span class="kw">starts_with</span>(<span class="st">&quot;z&quot;</span>)) %&gt;%<span class="st"> </span><span class="kw">as.matrix</span>()
<span class="co"># The models&#39; predictions for sample 2</span>
pred_a &lt;-<span class="st"> </span>X2_a %*%<span class="st"> </span>est_a
pred_b &lt;-<span class="st"> </span>X2_b %*%<span class="st"> </span>est_b</code></pre></div>
<p>Finally, let’s evaluate the two models’ predictions! We will calculate (1) mean absolute error (MAE), (2) mean squared error (MSE), and (3) mean absolute percentage error (MAPE).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate the error</span>
error_a &lt;-<span class="st"> </span>y2 -<span class="st"> </span>pred_a
error_b &lt;-<span class="st"> </span>y2 -<span class="st"> </span>pred_b
error_mat &lt;-<span class="st"> </span><span class="kw">cbind</span>(error_a, error_b)
<span class="kw">colnames</span>(error_mat) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;a&quot;</span>, <span class="st">&quot;b&quot;</span>)
<span class="co"># Mean abs. error</span>
mae &lt;-<span class="st"> </span><span class="kw">apply</span>(
  <span class="dt">X =</span> error_mat,
  <span class="dt">FUN =</span> . %&gt;%<span class="st"> </span><span class="kw">abs</span>() %&gt;%<span class="st"> </span><span class="kw">mean</span>(),
  <span class="dt">MARGIN =</span> <span class="dv">2</span>
)
<span class="co"># Mean squared error</span>
mse &lt;-<span class="st"> </span><span class="kw">apply</span>(
  <span class="dt">X =</span> error_mat,
  <span class="dt">FUN =</span> . %&gt;%<span class="st"> </span><span class="kw">raise_to_power</span>(<span class="dv">2</span>) %&gt;%<span class="st"> </span><span class="kw">mean</span>(),
  <span class="dt">MARGIN =</span> <span class="dv">2</span>
)
<span class="co"># Mean absolute percentage error</span>
mape &lt;-<span class="st"> </span><span class="kw">apply</span>(
  <span class="dt">X =</span> error_mat,
  <span class="dt">FUN =</span> . %&gt;%<span class="st"> </span><span class="kw">divide_by</span>(y2) %&gt;%<span class="st"> </span><span class="kw">abs</span>() %&gt;%<span class="st">  </span><span class="kw">mean</span>(),
  <span class="dt">MARGIN =</span> <span class="dv">2</span>
)
<span class="co"># Print a table of results</span>
res_mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data =</span> <span class="kw">c</span>(mae, mse, mape), <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">byrow =</span> T)
<span class="kw">rownames</span>(res_mat) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;MAE&quot;</span>, <span class="st">&quot;MSE&quot;</span>, <span class="st">&quot;MAPE&quot;</span>)
res_mat %&gt;%<span class="st"> </span>knitr::<span class="kw">kable</span>(
  <span class="dt">digits =</span> <span class="dv">3</span>,
  <span class="dt">row.names =</span> T,
  <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;Model a&quot;</span>, <span class="st">&quot;Model b&quot;</span>),
  <span class="dt">caption =</span> <span class="st">&quot;Evaluating the two models&#39; out-of-sample prediction performances&quot;</span>
)</code></pre></div>
<table>
<caption>Evaluating the two models’ out-of-sample prediction performances</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Model a</th>
<th align="right">Model b</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MAE</td>
<td align="right">0.755</td>
<td align="right">0.802</td>
</tr>
<tr class="even">
<td>MSE</td>
<td align="right">0.908</td>
<td align="right">1.020</td>
</tr>
<tr class="odd">
<td>MAPE</td>
<td align="right">0.608</td>
<td align="right">0.643</td>
</tr>
</tbody>
</table>
<p>So what’s the point here? Across three standard measures of prediction performance, as simple regression model with an intercept and a single covariate outperforms a model with the same intercept and covariate plus 100 other variables. What if we used within-sample R<sup>2</sup> as a way to assess model performance?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(y1 ~<span class="st"> </span>-<span class="dv">1</span> +<span class="st"> </span>X1_a) %&gt;%<span class="st"> </span><span class="kw">summary</span>() %$%<span class="st"> </span><span class="kw">c</span>(r.squared, adj.r.squared)</code></pre></div>
<pre><code>## [1] 0.9848760 0.9848457</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(y1 ~<span class="st"> </span>-<span class="dv">1</span> +<span class="st"> </span>X1_b) %&gt;%<span class="st"> </span><span class="kw">summary</span>() %$%<span class="st"> </span><span class="kw">c</span>(r.squared, adj.r.squared)</code></pre></div>
<pre><code>## [1] 0.9864762 0.9849401</code></pre>
<p>Within-sample, both the R<sup>2</sup> and the adjusted R<sup>2</sup> are higher for model <em>b</em> relative to model <em>a</em>.</p>
<p>We’re overfitting, and some of the classic econometric tools (measures of fit) did not help us avoid the problem. To be fair, we might avoid this problem by choosing a different measure of fit—for instance, instead of R<sup>2</sup> we could implement some sort of model-selection process based upon AIC(C) or BIC. But why stop there? AIC and BIC are just two ways we can try to avoid overfitting a model, so why not check out the full suite? This setting is where cross validation shines.</p>
</div>
<div id="train-validate-test" class="section level2">
<h2>Train, validate, test</h2>
<p>At the heart of cross validation are <em>train, validate, test</em>.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> We’ve actually already started applying these principles<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> above when we split our dataset in half, <em>trained</em> the two competing models on half the data (<span class="math inline">\(\mathbf{S}_1\)</span>) and then <em>validated</em> the models on the hold-out (or validation) dataset <span class="math inline">\(\mathbf{S}_2\)</span>. Let’s define these concepts a bit more.</p>
<p>Let’s imagine we have a dataset. In the train-validate-test cross-validation paradigm, we will split our dataset into subsets, corresponding to training, validating, and testing.</p>
<ol style="list-style-type: decimal">
<li><strong>Train</strong>: Generally the largest share (<em>e.g.</em>, 70–80%) of your full dataset goes into the training dataset. The essence: You have a bunch of data and a few models; you fit (train) your models using the training data.</li>
<li><strong>Validate</strong>: Once you fit your models on the training data, you evaluate (validate) their performance using data the models have never seen before—the <em>validation</em> dataset. You can iterate here—moving back and forth between the training and validation datasets, tuning your models (hyperparameters). But as you iterate between your training and validation datasets, you can also return to the world of overfitting—this time overfitting your validation dataset.</li>
<li><strong>Test</strong>: The testing dataset sits locked away<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>, waiting for you to finish training, tuning, and validating your model. Once you settle on an implementation/specification of your model, you train it one last time, unlock the testing dataset, and test your model’s performance on the testing dataset—your model has never seen these data, so you get a nice out-of-sample, not-overfit evaluation of your model’s performance.</li>
</ol>
<p>The discussion above treats the training and validation sets as mutually exclusive, but this need not be the case. There are several methods—<em>e.g.</em>, leave-one-out cross validation (LOOCV) and k-fold cross validation—that allow observations (or sets of observation) to “take turns” being in each groups. Our example above was essentially 2-fold cross validation.</p>
</div>
<div id="training-and-testing-errors" class="section level2">
<h2>Training and testing errors</h2>
<p>You might hear the distinction between <em>training</em> error (rate) and <em>testing</em> error (rate). These error rates emphasize the effect of overfitting and are (unsurprisingly) related to cross validation. The training error (rate) tells you how well your model performs when predicting the data on which the model was trained. The testing error (rate) tells you how well your model performs when predicting data it has never seen. The former can clearly suffer from overfitting, while the latter does not.</p>
<p>Let’s check the training and testing error for the two models in the previous empirical example. We’ll stick with mean absolute error for now.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate the MAE of the training and testing errors</span>
cv_errors &lt;-<span class="st"> </span><span class="kw">matrix</span>(
  <span class="dt">data =</span> <span class="kw">c</span>(
    <span class="kw">abs</span>(y1 -<span class="st"> </span>X1_a %*%<span class="st"> </span>est_a) %&gt;%<span class="st"> </span><span class="kw">mean</span>(),
    <span class="kw">abs</span>(y1 -<span class="st"> </span>X1_b %*%<span class="st"> </span>est_b) %&gt;%<span class="st"> </span><span class="kw">mean</span>(),
    <span class="kw">abs</span>(y2 -<span class="st"> </span>X2_a %*%<span class="st"> </span>est_a) %&gt;%<span class="st"> </span><span class="kw">mean</span>(),
    <span class="kw">abs</span>(y2 -<span class="st"> </span>X2_b %*%<span class="st"> </span>est_b) %&gt;%<span class="st"> </span><span class="kw">mean</span>()
  ), <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">byrow =</span> T
)
<span class="kw">rownames</span>(cv_errors) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Training error&quot;</span>, <span class="st">&quot;Testing error&quot;</span>)
<span class="co"># Print a nice table</span>
cv_errors %&gt;%<span class="st"> </span>knitr::<span class="kw">kable</span>(
  <span class="dt">digits =</span> <span class="dv">3</span>,
  <span class="dt">row.names =</span> T,
  <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;Model a&quot;</span>, <span class="st">&quot;Model b&quot;</span>),
  <span class="dt">caption =</span> <span class="st">&quot;Comparing the training and testing mean abs. error for the two models&quot;</span>
)</code></pre></div>
<table>
<caption>Comparing the training and testing mean abs. error for the two models</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Model a</th>
<th align="right">Model b</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Training error</td>
<td align="right">0.769</td>
<td align="right">0.725</td>
</tr>
<tr class="even">
<td>Testing error</td>
<td align="right">0.755</td>
<td align="right">0.802</td>
</tr>
</tbody>
</table>
<p>Unsurprisingly, the training error of model b is lower than the training error of model a—model b uses 100 more degrees of freedom to fit the data. However, as a result of overfitting, the testing error of model b is higher than the testing error of model a. This tradeoff is central to much of the statistical/machine learning literature: when do we want to add some more flexibility to our model (increasing the potential better fit but also increasing the potential for overfitting) and when do we just keep things simple? There are actually a lot of similar tradeoffs in the land of prediction.</p>
</div>
</div>
<div id="machines-learning" class="section level1">
<h1>Machines, learning</h1>
<p>The world of machine learning is a vast and rapidly developing place. As with most topics, there are many ways to divide up the space. That said, one of the most common ways to split learning models is between <em>supervised</em> and <em>unsupervised</em> algorithms.</p>
<ul>
<li><strong>Supervised algorithms</strong> have an outcome that they try to predict. This outcome can be qualitative (<em>e.g.</em>, text, categories, logical outcomes) or quantitative (real numbers, integers, binary), but the main point is that supervised learning algorithms need a known outcome variables. These algorithms use an assortment of statistical/mathematical methods, in conjunction with some objective function, to <em>learn</em> the value of the outcome variable from the rest of the data. <em>Examples</em>: decision trees, random forests, lasso regression, neural networks.</li>
<li>As you might guess, <strong>unsupervised algorithms</strong> do not have a known outcome variable. Instead, they take data on a set of observations—coupled with some measure of likeness—and then try to <em>learn</em> groupings that best describe the data. <em>Examples</em>: k-means (or k-medoids) clustering, hierarchical clustering, spectral clustering.</li>
</ul>
<p>Because most of the current machine-learning methods used in applied economics are supervised algorithms, we’re going to focus on on supervised algorithms today.</p>
<div id="decision-trees" class="section level2">
<h2>Decision trees</h2>
<p>Decision trees are one of the most-common and easiest-to-implement machine learning algorithms.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> They also (sometimes) provide a more interpretable final model, relative to other learning methods, though this is not always the case.</p>
<p>Let’s dive in. First, we need some data. Many of the classic applications of decision trees use binary outcomes,<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> so we’re going to load a (tragic) dataset with a binary outcome that has become a pretty standard example for decision trees: the survival passengers on the Titanic. The data come from <a href="https://www.kaggle.com/c/titanic/data">Kaggle</a>, and you can learn more about the variables on the <a href="https://www.kaggle.com/c/titanic/data">Kaggle competition website</a>.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> Decision trees that choose between categories are classification trees; decision trees that output a number are regression trees.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the training and testing datasets</span>
train_df &lt;-<span class="st"> </span><span class="kw">paste0</span>(dir_15, <span class="st">&quot;titanicTrain.csv&quot;</span>) %&gt;%<span class="st"> </span><span class="kw">read_csv</span>()</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   PassengerId = col_integer(),
##   Survived = col_integer(),
##   Pclass = col_integer(),
##   Name = col_character(),
##   Sex = col_character(),
##   Age = col_double(),
##   SibSp = col_integer(),
##   Parch = col_integer(),
##   Ticket = col_character(),
##   Fare = col_double(),
##   Cabin = col_character(),
##   Embarked = col_character()
## )</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_df &lt;-<span class="st"> </span><span class="kw">paste0</span>(dir_15, <span class="st">&quot;titanicTest.csv&quot;</span>) %&gt;%<span class="st"> </span><span class="kw">read_csv</span>()</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   PassengerId = col_integer(),
##   Pclass = col_integer(),
##   Name = col_character(),
##   Sex = col_character(),
##   Age = col_double(),
##   SibSp = col_integer(),
##   Parch = col_integer(),
##   Ticket = col_character(),
##   Fare = col_double(),
##   Cabin = col_character(),
##   Embarked = col_character()
## )</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Check our data</span>
train_df</code></pre></div>
<pre><code>## # A tibble: 891 x 12
##    PassengerId Survived Pclass Name   Sex     Age SibSp Parch Ticket  Fare
##          &lt;int&gt;    &lt;int&gt;  &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;
##  1           1        0      3 Braun… male    22.     1     0 A/5 2…  7.25
##  2           2        1      1 Cumin… fema…   38.     1     0 PC 17… 71.3 
##  3           3        1      3 Heikk… fema…   26.     0     0 STON/…  7.92
##  4           4        1      1 Futre… fema…   35.     1     0 113803 53.1 
##  5           5        0      3 Allen… male    35.     0     0 373450  8.05
##  6           6        0      3 Moran… male    NA      0     0 330877  8.46
##  7           7        0      1 McCar… male    54.     0     0 17463  51.9 
##  8           8        0      3 Palss… male     2.     3     1 349909 21.1 
##  9           9        1      3 Johns… fema…   27.     0     2 347742 11.1 
## 10          10        1      2 Nasse… fema…   14.     1     0 237736 30.1 
## # ... with 881 more rows, and 2 more variables: Cabin &lt;chr&gt;,
## #   Embarked &lt;chr&gt;</code></pre>
<p>I’m going to first fit a fairly simple tree, and then we can work through the basics of decision trees. For fitting a decision tree to a set of data, I will use the <code>rpart()</code> function from the <code>rpart</code> package. <code>rpart()</code> wants a formula—just like you would feed to <code>lm()</code>—in addition to a dataset and a method (<em>e.g.</em>, <code>&quot;class&quot;</code> for classification). We will predict a passenger’s survival using her sex, age, and class (currently treated as an integer). Note that <code>rpart()</code> defaults to dropping observations that have any missing values for the variables included in the formula. This decision can really affect results, and you should think about whether it makes sense in your setting.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit a tree on sex, age, and class</span>
tree1 &lt;-<span class="st"> </span><span class="kw">rpart</span>(
  Survived ~<span class="st"> </span>Sex +<span class="st"> </span>Age +<span class="st"> </span>Pclass,
  <span class="dt">data =</span> train_df,
  <span class="dt">method =</span> <span class="st">&quot;class&quot;</span>
)</code></pre></div>
<p>We can now plot the fitted tree using the <code>rpart.plot()</code> function from the <code>rpart.plot</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plot tree1</span>
<span class="kw">rpart.plot</span>(
  tree1,
  <span class="dt">branch.lty =</span> <span class="dv">3</span>,
  <span class="dt">box.palette =</span> <span class="kw">viridis</span>(<span class="dv">10</span>, <span class="dt">alpha =</span> <span class="fl">0.7</span>)
)</code></pre></div>
<p><img src="section15_files/figure-html/dt%20plot1-1.png" width="672" /></p>
</div>
<div id="lasso" class="section level2">
<h2>Lasso</h2>
<p>In empirical economics, you will likely came across <em>lasso</em> regressions. Besides having a pretty awesome name<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>, lasso provides a nice stepping point for social scientists who are used to linear regression models.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>We also made similar restrictions in the land of asymptopia.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Or sometimes just train and test.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Albeit somewhat haphazardly.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Sometimes literally.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>It’s probably no accident that these two attributes are found together.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p><em>e.g.</em>, a <em>decision</em> between ‘yes’ and ‘no’.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>We get a training dataset and a testing dataset, but to test the data, we need to upload our predictions to Kaggle’s website.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Much cooler than <em>ordinary least squares</em>.<a href="#fnref8">↩</a></p></li>
</ol>
</div>

<!-- <?php include_once("analyticstracking.php") ?> -->

<!-- For Google Analytics: -->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88887510-2', 'auto');
  ga('send', 'pageview');

</script>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
