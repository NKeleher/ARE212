---
title: "Section 12: Spatial data"
header-includes:
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: false
    toc_float:
      collapsed: false
      smooth_scroll: true
---

<br>

# Admin

## Announcements

<!-- TODO -->

## Last section

In our [previous section](section11.html) we covered instrumental variables and two-state least squares—two tools an econometrician can use against the bias/inconsistency generated by omitted variable, measurement error, and simultaneous equations.

### Follow up: Papers

### Follow up: Creative specification

<!-- TODO: good IV papers and including the instrument in the regression -->

## This week

This week we move a bit away from econometric techniques and instead focus on a class of data: _spatial_ data. Spatial data are increasingly important to economic research. They also provide researchers with a few unique challenges and thus warrant a few unique tools.

## What you will need

__Packages__:

- New:
    - Package management: `pacman`
    - Spatial: `rgdal`, `raster`, `broom`
    - Dates: `lubridate`
- Old: `dplyr`, `ggplot2`, `ggthemes`, `magrittr`, `viridis`

__Data__:

- The folder "ChicagoPoliceBeats", which contains the shapefile of Chicago's police beats.
- The file "chicagoCrime.rds".

<!-- TODO -->

# Spatial data

As I mentioned above, today we are focusing on a class of data, rather than a specific set of econometric techniques. The reason for this change is manyfold.

1. Spatial data are increasingly important within research—economics, environmental studies, development, agriculture, political science all are increasingly utilizing spatial variation. Spatial variation is important in many data-generating processes (_e.g._, the effects of air pollution), and it also can provide some compelling natural experiments (_e.g._, the rollout of a new policy throughout a country). Furthermore, some topics simply cannot be analyzed well without analyzing the topic _in space_, _e.g._, gerrymandering, segregation, or well depletion.
2. Spatial data are fairly distinct from other types of data in their structure. These structural differences tend to require unique techniques for compiling, describing, and analyzing the data. Why the difference? Spatial data have more dimensions than most other datasets that we use. Rather than a value connected to a time, we usually have a value connected to a latitude and a longitude–perhaps coupled with time and/or elevation. This difference is not _huge_; it just requires
3. Maps are awesome.^[Fact.]

Following the theme of section this semester, I am going to show you how to get started with spatial data in R. Of course, there are other tools. [ArcGIS](https://www.arcgis.com/) is probably the most well-known name in GIS (geographic information systems), but it is proprietary, expensive, and only works with Windows. If you really need it, there are several labs on campus that provide access—see the [D-Lab](http://dlab.berkeley.edu/space). [QGIS](http://www.qgis.org/) provides a free, open-source, cross-platform alternative to ArcGIS. We'll stick with R today; it's free, it's open source, and you are fairly familiar with it. Plus there's a nice online community of people using R for GIS, so you can (usually/eventually) find solutions when things go wrong. Finally, because you will likely use R for the econometrics in your research, using are for your GIS allows you to minimize the number of programs/scripts required during the course of your analysis.

Now that I've (hopefully) convinced you, let's get started.

## R setup

Set up R. Notice that I am using a new package `pacman`, which helps with package management. Specifically, I'm using `pacman`'s function `p_load()`, which allows you to load multiple packages with a single call to the function, rather than needing to type `library()` for each package that you want to load.

```{R, r setup, message = F}
# General R setup ----
# Options
options(stringsAsFactors = F)
# Load new packages
pacman::p_load(lubridate, rgdal, raster, broom)
# Load old packages
pacman::p_load(dplyr, ggplot2, ggthemes, magrittr, viridis)
# My ggplot2 theme
theme_ed <- theme(
  legend.position = "bottom",
  panel.background = element_rect(fill = NA),
  # panel.border = element_rect(fill = NA, color = "grey75"),
  axis.ticks = element_line(color = "grey95", size = 0.3),
  panel.grid.major = element_line(color = "grey95", size = 0.3),
  panel.grid.minor = element_line(color = "grey95", size = 0.3),
  legend.key = element_blank())
# My directory
dir_12 <- "/Users/edwardarubin/Dropbox/Teaching/ARE212/Section12/"
```

## Types of data

There are two basic types of spatial: __vector__ and __raster__. _Vector_ data include points, lines, and polygons—the things generally contained in files called _shapefiles_. _Raster_ data are comprised of single raster layers and raster stacks (stacks of raster layers) and are essentially images—values mapped to a grid.

# Vector data

You will generally encounter vector data as shapefiles (extension `.shp`). However, you will also encounter vectors as datasets of points that include the coordinates of observations and some information about those points (often `.csv`). At their core, all vector files are simply collections of points. For points-based files, this statement is obvious. Lines and polygons are collections of points, so again, we see that the classes of objects that make up vectors are "simply" collections of points.

## Loading a shapefile

Let's load a shapefile. Specifically, we will load the polygons that compose the police beats for the city of Chicago.^[I downloaded these data from [Chicago's data portal](https://data.cityofchicago.org/).] To read in the shapefile that comprises these spatial data, we will use the `readOGR()` function from the package `rgdal`. The function needs two arguments: `dsn`, which is generally the folder that contains the shapefile, and `layer`, which is generally the name of the shapefile (omitting the `.shp` extension). In our case, the name of the folder is "ChicagoPoliceBeats", and the name of the shapefile is "chiBeats.shp". Let's load the shapefile!

```{R, load beats shp}
# Load the shapefile with the Chicago beats data
beats_shp <- readOGR(
  dsn = paste0(dir_12, "ChicagoPoliceBeats"),
  layer = "chiBeats")
```

Now, let's check a few things—the class of the object we just read into R, its dimensions, and plotting it.

```{R, check beats shapefile, fig.height = 6}
# Class
class(beats_shp)
# Dimensions
dim(beats_shp)
# Plot
plot(beats_shp)
```

Cool, right? So what does it mean that this "spatial polygons data frame" has dimensions 277 and 4? The first number is generally the number of distinct shapes in the shapefile. In our case, we 277 polygons. And what about the second number? The second number gives us the number of attributes—essentially the number of variables for which we have information for each polygon.

## Decomposing a shapefile

We can dive a bit deeper into the data that compose a shapefile in R. Up to this point, you've seen that you can access the columns of a `data.frame`^[or `tibble` or `tbl_df` or `data.table`] using the dollar sign, _e.g._, `pretend_df$variable1`. Spatial data frames add an additional level—we now have slots. You can still find out the names of the attribute (variables) using `names(beats_shp)`, but now you can also find the names of the _slots_ using `slotNames(beats_shp)`:

```{R, slot names}
# Attribute/variable names
names(beats_shp)
# Slot names
slotNames(beats_shp)
```

The `data` slot is a data frame like we've seen before, but now there are other slots related to our spatial data: the polygons, the plot order (`plotOrder`), the bounding box (`bbox`), and the `proj4string` (a string that encodes the projection used for the polygons' coordinates).

Let's take a look at the data slot. To access the slots, use the slot's name in conjunction with an ampersat, _e.g._, `beats_shp@data`

```{R, data slot}
# Check the class of the object in the 'data' slot
beats_shp@data %>% class()
# Check the head of the object in the 'data' slot
beats_shp@data %>% head()
# Check the head of the object in the 'data' slot
beats_shp@data %>% dim()
```

Let's see what objects are in the other slots.

```{R, more slots}
# 'plotOrder' slot
beats_shp@plotOrder %>% head()
# 'bbox' slot
beats_shp@bbox
# 'proj4string' slot
beats_shp@proj4string
```

Finally, let's investigate the `polygons` slot. What is the class?
```{R, polygons slot}
# Find the class
beats_shp@polygons %>% class()
# Find the length of the list
beats_shp@polygons %>% length()
```

A list of length 277! Where have we seen the number 277 before? The dimensions of the `beats_shp` and the number of rows in the data frame in the `data` slot. The `polygons` slot is a list whose elements are the individual polygons that make up the shapefile.

What is the class of a single polygon (a single element of the list in the `polygons` slot)?^[Recall that we use `a_list[[n]]` to access the n^th^ object of the list `a_list`.]
```{R, a polygon}
# Class of the first element in the 'polygons' slot
beats_shp@polygons[[1]] %>% class()
```

This polygon object has the class `Polygons`, which is simultaneously fitting and uninformative. Are you ready to get a bit meta? The polygons in the `polygons` slot have slots of their own. Let's see the names of the slots for a single polygon in the `polygons` slot.

```{R, polygon slots}
# Slot names for a polygon
beats_shp@polygons[[1]] %>% slotNames()
```

Let's (quickly) continue down this rabbit hole, accessing the `Polygons` slot and checking its class.
```{R, polygons polygons}
# What is the class?
beats_shp@polygons[[1]]@Polygons %>% class()
# What is the length?
beats_shp@polygons[[1]]@Polygons %>% length()
```

Another list, but this list is only of length one. Let's access the single element in this list and then check the slot names on last time.
```{R, deep in the rabbit hole}
# Deep in the rabbit hole
beats_shp@polygons[[1]]@Polygons[[1]] %>% slotNames()
```

Finally, we see a slot name `coords`. These are the coordinates of the points that make up the first polygon in our shapefile. Let's check the head and dimensions of this object then plot its points.
```{R, first polygon points}
# The head of the coordinates
beats_shp@polygons[[1]]@Polygons[[1]]@coords %>% head()
# The dimensions of the coordinates
beats_shp@polygons[[1]]@Polygons[[1]]@coords %>% dim()
# Plot the coordinates
beats_shp@polygons[[1]]@Polygons[[1]]@coords %>% plot()
```

Thus, we see that the first polygon is made up of 345 coordinates that jointly determine area for beat number 1713 (the first row in `beats_shp@data`). We can confirm that these points match the polygon for beat number 1713 by taking the `subset()` of `beats_shp`:
```{R, plot 1713}
subset(beats_shp, beat_num == "1713") %>% plot()
```

So what have we learned, thus far, about this shapefile? The shapefile is made up of polygons, and each polygon is made up of points on a coordinate system—in this case, longitudes ($x$) and latitudes ($y$). When you plot the points using their coordinates and then connect the dots (points), you get a polygon. Together, the polygons determine the shapefile. In addition to shapes of the polygons, we also have data (in the `data` slot) about each polygons. In the current examples, we have four attributes about the polygons, but in other cases, you will know a lot more about each polygon—for instance, Census will have hundreds of attributes for each polygon (the polygons are the Census blocks, tracts, _etc._).

## Building a shapefile

We can also move in the opposite direction:

1. Create a data frame with two columns for the coordinates.
2. Convert the data frame to a matrix.
3. Convert the matrix of coordinates to a polgyon using `Polygon()`.
4. Create a `Polygons` object using a list and the function `Polygons()`.
5. Create a `SpatialPolygons` object from a list the `Polygons` object(s).
6. Create a `SpatialPolygonsDataFrame` from the `SpatialPolygons` object and a data frame.

```{R, build shapefile}
# Create coordinates in data.frame
coord_df <- data.frame(
  x = c(0, 0, 1, 2, 1, 1),
  y = c(0, 1, 1, 0, 0, -1))
# Convert data.frame to matrix
coord_mat <- coord_df %>% as.matrix()
# Create a Polygon
the_polygon <- Polygon(coord_mat)
# Create the Polygons object
the_polygons <- Polygons(list(the_polygon), 1)
# Create the SpatialPolygons object
the_sp <- SpatialPolygons(list(the_polygons))
# Create a SpatialPolygonsDataFrame
the_spdf <- SpatialPolygonsDataFrame(the_sp,
  data = data.frame(a = 12, b = 6))
```

Now let's check our work:
```{R, plot built shapefile}
# Plot 'the_spdf'
plot(the_spdf)
# Check the data slot
the_spdf@data
```

__Notes__:

1. Notice that we created the polygon by plotting the points __in the order that they are listed__ (and connecting the last point to the first point).
2. In this example, we created only one polygon, but the process is similar for multiple polygons.

## Plotting shapefiles with `ggplot2`

You've already seen that we can use R's base `plot()` function to plot shapefiles, but what if we want to use `ggplot2`? In this situation, `ggplot2` still produces pretty pictures, but it can be much slower than `plot()` when you have a lot of polygons with many points. Plot at your own risk.^[If it is taking too long, try saving the plot, rather than printing it to screen.]

Okay, so let's plot the police beats shapefile. `ggplot2` wants a data frame where each row is a point. As we saw above, we're almost there—the polygons are composed of points—but we need to formally convert the spatial polygons data frame to a data frame. For this task, I suggest the `tidy()` function from the `broom` package.^[You can use this `tidy()` function for tidying up all kinds of objects.] We simply feed our shapefile (the spatial polygons data frame `beats_shp`) to `tidy()`, and we get back a data frame where each row is a point in one of the polygons in the shapefile. This process can take a while and can also take up a lot of memory if you have many polygons with many points.

```{R, tidy shapefile}
# Tidy the shapefile
beats_df <- tidy(beats_shp)
# Look at the first three rows
beats_df %>% head(3)
```

Now we are ready to plot. The syntax for `ggplot2` remains the same. We need to map the `x` and `y` aesthetics (longitude and latitude), as well as the `group` (the polygon). For the actual plotting, we can use `geom_path()`—for only the outline of the polygons—and/or `geom_polygon()`, which allows for filling the polygons with color. `geom_map` is another nice option, but I will stick to `geom_path()` and `geom_polygon()` because they are a bit clearer. Finally, the `coord_map()` function allows you to specify a projection for the map. If you've ever seen maps that look a bit strange, it was probably because they used a different projection.^[See `?coor_map` for more information.]

```{R, plot shapefile, fig.height = 7}
# Plot the tidied shapefile
ggplot(data = beats_df, aes(x = long, y = lat, group = group)) +
  geom_polygon(fill = "grey90") +
  geom_path(size = 0.3) +
  xlab("Longitude") +
  ylab("Latitude") +
  ggtitle("Chicago police beats") +
  theme_ed +
  coord_map()
```

## Points data

In addition to shapefiles, the second type of vector data you will often encounter is point data. These files are exactly what they sound like: each observation (row) contains coordinates for a point in space and information on some set of variables.

Let's load a points dataset. The file `chicagoCrime.rds` containts Chicago's police incident reports data from 2010 to the present (again, downloaded from [Chicago's data portal](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2)). The actual dataset has a few more variables and goes back to 2001, but I wanted to keep the file a bit smaller. I've saved the file as an `.rds` file, which is an R-specific format that offers a lot of compression, substantially reducing the size of the file. To load an `.rds` file, you can use the `readRDS()` function (or `readr`'s `read_rds()` function, which is just a wrapper for `readRDS()`). Let's load it.

```{R, load crime data}
# Read crime points data file
crime_df <- readRDS(paste0(dir_12, "chicagoCrime.rds"))
# Convert to tbl_df
crime_df %<>% tbl_df()
# Check it out
crime_df
```

Let's clean up the file a bit more. First, we will change the names of the variables. Second, we will convert the dates from character to actual dates using the function `mdy_hms()` from the `lubridate` package. The `mdy` part of the function's name implies that the dates have month first, followed by day, follwed by year. The `hms` part of the function's name implies that we have hours, minutes, and seconds. If you did not have hours, minutes, and seconds, then you would want to use the function `mdy()`. If you had year, followed by month, followed by day, then you would want to use the function `ymd()`. And so on....

```{R, clean crime data}
# Change names
names(crime_df) <- c("id", "date", "primary_offense",
  "arrest", "domestic", "beat", "latitude", "longitude")
# Convert dates
crime_df %<>% mutate(date = mdy_hms(date))
# Check it out again
crime_df
```

Great! Now let's plot the points data.

## Plotting points data with `ggplot2`



<!-- TODO -->

# Raster data



# Projections

Let's return to the `proj4string` slot for a moment. This slot contains the projection (coordinate reference system or CRS) used in creating the shapefile. [Different projections](https://xkcd.com/977/) yield different sets of coordinates. Thus, if your projects entails multiple datasets—as most do—then you need to make sure that you are using a consistent projection across all of your datasets/files. If you do not, then (0, 0) in one of your datasets may actually be (180, 180) in another of your datasets—nothing will line up (or it will erroneously line up). Be careful here. For information on how to change projections, see the help files `?raster::crs`, `?rgdal::spTransform`, the [`proj4` package](https://cran.r-project.org/web/packages/proj4/proj4.pdf), and/or the [proj.4 website](http://proj4.org/)).









# QGIS

<!-- TODO -->

# Other resources

If you are interested in learing more about spatial data, check out [Sol Hsiang](http://globalpolicy.science/solomon-hsiang)'s course, Public Policy 290.

Here are a few more resources for utilizing spatial data in R.

- http://www.nickeubank.com/wp-content/uploads/2015/10/gis_in_r_vector_cheatsheet.pdf
- https://science.nature.nps.gov/im/datamgmt/statistics/r/advanced/spatial.cfm
- https://www.datacamp.com/courses/working-with-geospatial-data-in-r
- http://www.rspatial.org/
- https://pakillo.github.io/R-GIS-tutorial/
- http://spatial.ly/r/
- https://cran.r-project.org/doc/contrib/intro-spatial-rl.pdf
- ftp://ftp.bgc-jena.mpg.de/pub/outgoing/mforkel/Rcourse/spatialR_2015.pdf

# Fun tools: Vivaldi

Example: https://fieldguide.gizmodo.com/5-reasons-to-use-to-vivaldi-instead-of-chrome-or-firefo-1771284757
